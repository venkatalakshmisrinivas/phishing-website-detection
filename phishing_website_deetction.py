# -*- coding: utf-8 -*-
"""phishing website deetction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bKJ8hUD9QMiNx2_7y6HDnaV-QVtky-Az
"""

import numpy as np
import pandas as pd

raw_data = pd.read_csv("100-legitimate-art.txt")

raw_data.head()

raw_data['websites'].str.split("://").head()      # dividing the protocol from te URL

seperation_of_protocol = raw_data['websites'].str.split("://",expand = True)      # removing the HTTP from the url
seperation_of_protocol.head()

type(seperation_of_protocol)

seperation_domain_name = seperation_of_protocol[1].str.split("/",1,expand = True) #split(seperator,no of splits according to seperator(delimiter),expand)
type(seperation_domain_name)

seperation_domain_name.columns=["domain_name","address"]    #renaming columns of data frame
seperation_domain_name.head()

"""concatinating the protocol,domain name,address"""

splitted_data = pd.concat([seperation_of_protocol[0],seperation_domain_name],axis=1)
splitted_data.columns = ['protocol','domain_name','address']
splitted_data.head()

type(splitted_data)

"""the URL is divided into 3 categories based on lenth of URL"""

def long_url(l):
    if len(l) < 54:
        return 0
    elif len(l) >= 54 and len(l) <= 75:
        return 2
    return 1

splitted_data['long_url'] = raw_data['websites'].apply(long_url)
splitted_data[splitted_data.long_url == 0].head()

"""if the URL have symbols like'@'"""

def have_at_symbol(l):
    if "@" in l:
        return 1
    return 0

splitted_data['having_@_symbol'] = raw_data['websites'].apply(have_at_symbol)
splitted_data.head()

"""check whether URL has the symbol '//' """

def redirection(l):  
    if "//" in l:
        return 1
    return 0
splitted_data['redirection_//_symbol'] = seperation_of_protocol[1].apply(redirection)
splitted_data.head()

"""check whether URL has symbol '-'"""

def prefix_suffix_seperation(l):
    if '-' in l:
        return 1
    return 0
splitted_data['prefix_suffix_seperation'] = seperation_domain_name['domain_name'].apply(prefix_suffix_seperation)
splitted_data.head()

"""check whether the URL has symbol '.' or multi domain"""

def sub_domains(l):
    if l.count('.') < 3:
        return 0
    elif l.count('.') == 3:
        return 2
    return 1
splitted_data['sub_domains'] = splitted_data['domain_name'].apply(sub_domains)
splitted_data.head()

"""check whether the URL has ip addrss or not??"""

import re
def having_ip_address(url):
    match=re.search('(([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\.([01]?\\d\\d?|2[0-4]\\d|25[0-5])\\/)|'  #IPv4
                    '((0x[0-9a-fA-F]{1,2})\\.(0x[0-9a-fA-F]{1,2})\\.(0x[0-9a-fA-F]{1,2})\\.(0x[0-9a-fA-F]{1,2})\\/)'  #IPv4 in hexadecimal
                    '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}',url)     #Ipv6
    if match:
        #print match.group()
        return 1
    else:
        #print 'No matching pattern found'
        return 0
splitted_data['having_ip_address'] = raw_data['websites'].apply(having_ip_address)
splitted_data.head()

"""if the URL has 'HTTP' if id phished website"""

def https_token(url):
    match=re.search('https://|http://',url)
    if match.start(0)==0:
        url=url[match.end(0):]
    match=re.search('http|https',url)
    if match:
        return 1
    else:
        return 0
splitted_data['https_token'] = raw_data['websites'].apply(https_token)
splitted_data.head()

"""abnormal URL"""

def abnormal_url_sub(domain,url):
    hostname=domain.name
    match=re.search(hostname,url)
    if match:
        return 0
    else:
        return 1

"""statistical based report"""

import socket
def statistical_report(url):
    hostname = url
    h = [(x.start(0), x.end(0)) for x in re.finditer('https://|http://|www.|https://www.|http://www.', hostname)]
    z = int(len(h))
    if z != 0:
        y = h[0][1]
        hostname = hostname[y:]
        h = [(x.start(0), x.end(0)) for x in re.finditer('/', hostname)]
        z = int(len(h))
        if z != 0:
            hostname = hostname[:h[0][0]]
    url_match=re.search('at\.ua|usa\.cc|baltazarpresentes\.com\.br|pe\.hu|esy\.es|hol\.es|sweddy\.com|myjino\.ru|96\.lt|ow\.ly',url)
    try:
        ip_address = socket.gethostbyname(hostname)
        ip_match=re.search('146\.112\.61\.108|213\.174\.157\.151|121\.50\.168\.88|192\.185\.217\.116|78\.46\.211\.158|181\.174\.165\.13|46\.242\.145\.103|121\.50\.168\.40|83\.125\.22\.219|46\.242\.145\.98|107\.151\.148\.44|107\.151\.148\.107|64\.70\.19\.203|199\.184\.144\.27|107\.151\.148\.108|107\.151\.148\.109|119\.28\.52\.61|54\.83\.43\.69|52\.69\.166\.231|216\.58\.192\.225|118\.184\.25\.86|67\.208\.74\.71|23\.253\.126\.58|104\.239\.157\.210|175\.126\.123\.219|141\.8\.224\.221|10\.10\.10\.10|43\.229\.108\.32|103\.232\.215\.140|69\.172\.201\.153|216\.218\.185\.162|54\.225\.104\.146|103\.243\.24\.98|199\.59\.243\.120|31\.170\.160\.61|213\.19\.128\.77|62\.113\.226\.131|208\.100\.26\.234|195\.16\.127\.102|195\.16\.127\.157|34\.196\.13\.28|103\.224\.212\.222|172\.217\.4\.225|54\.72\.9\.51|192\.64\.147\.141|198\.200\.56\.183|23\.253\.164\.103|52\.48\.191\.26|52\.214\.197\.72|87\.98\.255\.18|209\.99\.17\.27|216\.38\.62\.18|104\.130\.124\.96|47\.89\.58\.141|78\.46\.211\.158|54\.86\.225\.156|54\.82\.156\.19|37\.157\.192\.102|204\.11\.56\.48|110\.34\.231\.42',ip_address)  
    except:
        return 1

    if url_match:
        return 1
    else:
        return 0

splitted_data['statistical_report'] = raw_data['websites'].apply(statistical_report)
splitted_data.head()